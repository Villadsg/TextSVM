{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a4f6075-637a-4131-b48f-0fe2a37ec1ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fd3b3c0-86fa-4b0b-9a39-023f0ab75e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\villa\\AppData\\Local\\Temp\\ipykernel_23564\\3363721854.py:17: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  data.B2StilD = data.B2StilD.str.replace('.', '')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load the data from the CSV file\n",
    "\n",
    "#load trianing data\n",
    "data = pd.read_csv('storfil.csv',sep=',',encoding = 'latin-1')\n",
    "\n",
    "#load disco code names\n",
    "format1 = pd.read_csv('csv_da.csv',sep=';',encoding = 'utf-8')[['KODE','TITEL']]\n",
    "format1['B2StilD'] = format1['KODE']\n",
    "\n",
    "\n",
    "#DROP NA\n",
    "data.dropna(subset=['B2StilD'], inplace =True)\n",
    "\n",
    "\n",
    "#remove dots from DISCO code\n",
    "data.B2StilD = data.B2StilD.astype(str)\n",
    "data.B2StilD = data.B2StilD.str.replace('.', '')\n",
    "\n",
    "#Comine disco code names with training data\n",
    "format1['KODE'] = format1['KODE'].astype(str)\n",
    "format1['KODE'] = format1['KODE'].str.slice(stop=4)\n",
    "format_grouped = format1.groupby('KODE').agg({'TITEL':''.join}).reset_index()\n",
    "data['B2StilD'] = data['B2StilD'].map(format_grouped.set_index('KODE')['TITEL'])\n",
    "\n",
    "\n",
    "#make B2stil + B2stilA\n",
    "data['B2Stilplus'] = data['B2Stil'] +' '+ data['B2StilA']\n",
    "\n",
    "\n",
    "#format_dict = format_grouped.set_index('KODE').to_dict()\n",
    "#data['B2StilD'] = data['B2StilD'].apply(lambda x: format_dict[x])\n",
    "\n",
    "#data = data.merge(format,on='B2StilD',how='left')\n",
    "#print(data['B2Stil'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af531f64-1b69-4139-b6cf-ac774a68e1de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# load the data from the CSV file\n",
    "data.dropna(subset=['B2StilD'], inplace =True)\n",
    "# define a list of stop words\n",
    "stop_words = set(stopwords.words('danish'))\n",
    "\n",
    "# define a stemmer\n",
    "stemmer = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdf4666e-3bd9-4edc-9e8b-7903aded3c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# define a function to preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    # convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # remove numbers\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    # tokenize the text into words\n",
    "    words = text.split()\n",
    "    # remove stop words\n",
    "    #words = [word for word in words if word not in stop_words]\n",
    "    # perform stemming\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    # join the words back into a single string\n",
    "    text = ' '.join(words)\n",
    "    return text\n",
    "\n",
    "# preprocess the text data\n",
    "#data['text'] = data['text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "793523b9-81c1-4206-806b-91920cf6b6a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               B2Stilplus\n",
      "0       MASKINOPERATØR står ved en maskine i produktio...\n",
      "1         DISPONENT Fordeler arbejdsopgaver på chauffører\n",
      "2       Lastbilchauffør - national transport Godstrans...\n",
      "3       sagsbehandler - socialrådgiver Vejledning af b...\n",
      "4              BIOANA Chef for nuklear medicinsk afdeling\n",
      "...                                                   ...\n",
      "148983                         adjunkt research, teaching\n",
      "148984  maskinfører Kører gravmaskine og diverse andre...\n",
      "148985  social og sundhedshjælper Passer og plejer æld...\n",
      "148986             sælger sælger og laver mad i pølsevogn\n",
      "148987                                  danser jeg danser\n",
      "\n",
      "[148988 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\villa\\AppData\\Local\\Temp\\ipykernel_23564\\1314178322.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  datab2stil = pd.DataFrame(datab2stil.append(new_sentence, ignore_index=True))\n"
     ]
    }
   ],
   "source": [
    "datab2stil =pd.DataFrame(data['B2Stilplus'])\n",
    "\n",
    "new_sentence = {'B2Stilplus': 'danser jeg danser'}\n",
    "datab2stil = pd.DataFrame(datab2stil.append(new_sentence, ignore_index=True))\n",
    "\n",
    "\n",
    "print(datab2stil)\n",
    "#print(datappend.iloc[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87422cc3-a02d-48c9-9369-4f7399c8ee84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danser jeg danser\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# preprocess the text data\n",
    "datab2stil['text1'] = datab2stil['B2Stilplus'].astype(str).apply(preprocess_text)\n",
    "#Not in use atm\n",
    "#data['text1'] = data['B2Stil'].astype(str).apply(preprocess_text)\n",
    "\n",
    "#data['text2'] = data['B2StilA'].astype(str).apply(preprocess_text)\n",
    "\n",
    "#data['text3'] = data['B2StilD'].astype(str).apply(preprocess_text)\n",
    "\n",
    "#data['combined'] = data.apply(lambda row: row['text1']+ '' + row['text2'],axis=1)\n",
    "\n",
    "#data['random'] = np.random.randint(0,100)\n",
    "\n",
    "print(datab2stil['text1'].iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c63b244-b061-405f-81ec-1e11c26dbb52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6736)\t0.9724369571259232\n",
      "  (0, 17072)\t0.23316595895558045\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# convert the text data into numerical features using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "#tfidf_features1 = tfidf_vectorizer.fit_transform(data['text1'])\n",
    "#tfidf_features2 = tfidf_vectorizer.fit_transform(data['text2'])\n",
    "#tfidf_featuresY = tfidf_vectorizer.fit_transform(data['text3'])\n",
    "tfidf_features4 = tfidf_vectorizer.fit_transform(datab2stil['text1'])\n",
    "\n",
    "# Get the indices of the last row\n",
    "last_doc_idx = tfidf_features4.shape[0] - 1\n",
    "\n",
    "#capture last row\n",
    "tfidf_newdata = tfidf_features4[-1, :]\n",
    "\n",
    "# Remove the last row\n",
    "tfidf_features4 = tfidf_features4[:last_doc_idx, :]\n",
    "\n",
    "\n",
    "print(tfidf_newdata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d853dab2-af1c-45be-a86b-e80e0629b5e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Fjern nye sætninger:\n",
    "\n",
    "\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_features4, data['B2StilD'], shuffle=False, stratify=None, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8640534f-89ee-4fdb-b67c-8085b102275b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6486341365192295\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train an SVM model on the training data\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# test the SVM model on the testing data\n",
    "accuracy = svm_model.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc7de93e-e00a-4e09-9e50-6a35e2988607",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 43667 features, but SVC is expecting 78626 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msvm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfidf_newdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\textml\\textml\\Lib\\site-packages\\sklearn\\svm\\_base.py:820\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    818\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\textml\\textml\\Lib\\site-packages\\sklearn\\svm\\_base.py:433\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \n\u001b[0;32m    420\u001b[0m \u001b[38;5;124;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 433\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m     predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\textml\\textml\\Lib\\site-packages\\sklearn\\svm\\_base.py:613\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    610\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[1;32m--> 613\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39misspmatrix(X):\n\u001b[0;32m    623\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\textml\\textml\\Lib\\site-packages\\sklearn\\base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\textml\\textml\\Lib\\site-packages\\sklearn\\base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 43667 features, but SVC is expecting 78626 features as input."
     ]
    }
   ],
   "source": [
    "svm_model.predict(tfidf_newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d0c0d6-5e9a-48e6-9f65-6f422cb4833c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
